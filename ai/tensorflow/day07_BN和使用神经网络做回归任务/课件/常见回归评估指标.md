# 常见回归评估指标

### 1 . 解释方差分(explained_variance_score)

explained_variance_score：解释方差分，这个指标用来衡量我们模型对数据集波动的解释程度，如果取值为1时，模型就完美，越小效果就越差.

$$explained\_variance(y,\hat{y}) = 1 - \frac{Var\{y - \hat{y}\}}{Var\{y\}}$$

其中y是真实值, $\hat{y}$是预测值, var是方差

```python
from sklearn.metrics import explained_variance_score

y_true = [3, -0.5, 2, 7]
y_pred = [2.5, 0, 2, 8]
explained_variance_score(y_true, y_pred)

# 多维的y值可以通过multioutput控制输出的得分维度.
y_true = np.array([[0.5, 1], [-1, 1], [7, -6]])
y_pred = np.array([[0, 2], [-1, 2], [8, -5]])
# 原始维度一个维度算一个得分
explained_variance_score(y_true, y_pred, multioutput='raw_values')
# 最终得分的比例
explained_variance_score(y_true, y_pred, multioutput=[0.3, 0.7])
```

### 2. Mean absolute error（平均绝对误差）

$$MAE(y, \hat{y}) = \frac{1}{n_{samples}}\sum^{n_{samples-1}}_{i=0}|y_{i} - \hat{y_{i}}|$$

其中y是真实值, $\hat{y}$是预测值

给定数据点的平均绝对误差，一般来说取值越小，模型的拟合效果就越好。

sklearn中的使用方法和解释方差分一样.

MAE是L1损失的期望.

### 3. Mean squared error（均方误差）

$$MSE(y, \hat{y}) = \frac{1}{n_{samples}}\sum^{n_{samples-1}}_{i=0}(y_{i} - \hat{y_{i}})^2$$

MSE是回归任务最常用的性能度量之一.

sklearn中的使用方法类似.

### 4. Mean squared logarithmic error(均方对数误差)

$$MSLE(y, \hat{y}) = \frac{1}{n_{samples}}\sum^{n_{samples-1}}_{i=0}(\log(1 + y_i) - \log(1 + \hat{y_i}))^2$$

当目标实现指数增长时，例如人口数量、一种商品在几年时间内的平均销量等，这个指标最适合使用。

y值存在负数的话,这个指标不能用.

### 5. Median absolute error（中位数绝对误差）

$$MedAE(y, \hat{y}) = median(|y_1 - \hat{y_1}|, ...,|y_n - \hat{y_n}|)$$

中位数绝对误差适用于包含异常值的数据的衡量.

### 6. R² score（决定系数、R方）

$$R^2(y, \hat{y}) = 1 - \frac{\sum^{n}_{i=1}(y_i - \hat{y_i})^2}{\sum^{n}_{i=1}(y_i - \bar{y_i})^2}$$

其中$\bar{y}$是y的平均值

R方是多元回归中的回归平方和占总平方和的比例,它是度量多元回归方程中拟合程度的一个统计量,反映了在因变量y的变差中被估计的回归方程所解释的比例。 
R越接近1,表明回归平方和占总平方和的比例越大,回归线与各观测点越接近,用x的变化来解释y值变差的部分就越多,回归的拟合程度就越好。

一般来说，增加自变量的个数，回归平方和会增加，残差平方和会减少，所以R方会增大；反之，减少自变量的个数，回归平方和减少，残差平方和增加。

